{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Semantic-based Chunking with Ragas\n",
    "\n",
    "This notebook compares the performance of a baseline RAG application using RecursiveCharacterTextSplitter against a semantic-based chunking approach using TOCChunker.\n",
    "\n",
    "## Notebook Structure\n",
    "1. Dependencies and Setup\n",
    "2. Baseline RAG Evaluation (RecursiveCharacterTextSplitter)\n",
    "3. Evaluating the TOCChunker\n",
    "4. Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and Setup\n",
    "\n",
    "Install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ragas in ./venv/lib/python3.13/site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.13/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-openai in ./venv/lib/python3.13/site-packages (0.3.28)\n",
      "Requirement already satisfied: langchain-community in ./venv/lib/python3.13/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-qdrant in ./venv/lib/python3.13/site-packages (0.2.0)\n",
      "Requirement already satisfied: langgraph in ./venv/lib/python3.13/site-packages (0.5.3)\n",
      "Requirement already satisfied: qdrant-client in ./venv/lib/python3.13/site-packages (1.15.0)\n",
      "Requirement already satisfied: pymupdf in ./venv/lib/python3.13/site-packages (1.26.3)\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.13/site-packages (1.97.0)\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.13/site-packages (11.3.0)\n",
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.13.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (from ragas) (2.3.1)\n",
      "Requirement already satisfied: datasets in ./venv/lib/python3.13/site-packages (from ragas) (4.0.0)\n",
      "Requirement already satisfied: tiktoken in ./venv/lib/python3.13/site-packages (from ragas) (0.9.0)\n",
      "Requirement already satisfied: langchain-core in ./venv/lib/python3.13/site-packages (from ragas) (0.3.69)\n",
      "Requirement already satisfied: nest-asyncio in ./venv/lib/python3.13/site-packages (from ragas) (1.6.0)\n",
      "Requirement already satisfied: appdirs in ./venv/lib/python3.13/site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: pydantic>=2 in ./venv/lib/python3.13/site-packages (from ragas) (2.11.7)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in ./venv/lib/python3.13/site-packages (from ragas) (5.6.3)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./venv/lib/python3.13/site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.13/site-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in ./venv/lib/python3.13/site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in ./venv/lib/python3.13/site-packages (from langgraph) (0.5.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in ./venv/lib/python3.13/site-packages (from langgraph) (0.1.73)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./venv/lib/python3.13/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in ./venv/lib/python3.13/site-packages (from qdrant-client) (1.73.1)\n",
      "Requirement already satisfied: httpx>=0.20.0 in ./venv/lib/python3.13/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
      "Requirement already satisfied: portalocker<4.0,>=2.7.0 in ./venv/lib/python3.13/site-packages (from qdrant-client) (3.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in ./venv/lib/python3.13/site-packages (from qdrant-client) (6.31.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in ./venv/lib/python3.13/site-packages (from qdrant-client) (2.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.13/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.13/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.13/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.13/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in ./venv/lib/python3.13/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core->ragas) (25.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./venv/lib/python3.13/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./venv/lib/python3.13/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic>=2->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic>=2->ragas) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic>=2->ragas) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.13/site-packages (from tiktoken->ragas) (2024.11.6)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.13/site-packages (from datasets->ragas) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./venv/lib/python3.13/site-packages (from datasets->ragas) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venv/lib/python3.13/site-packages (from datasets->ragas) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.13/site-packages (from datasets->ragas) (2.3.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./venv/lib/python3.13/site-packages (from datasets->ragas) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in ./venv/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./venv/lib/python3.13/site-packages (from datasets->ragas) (0.33.4)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in ./venv/lib/python3.13/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in ./venv/lib/python3.13/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./venv/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets->ragas) (1.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas->datasets->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\n",
      "Downloading rapidfuzz-3.13.0-cp313-cp313-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.13.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ragas langchain langchain-openai langchain-community langchain-qdrant langgraph qdrant-client pymupdf openai pillow rapidfuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up API keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Please enter your OpenAI API key!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# For debugging\n",
    "def printJSON(j):\n",
    "    output = json.dumps(j, indent=2)\n",
    "    lines = output.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline RAG Evaluation\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "Load the loan data documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "path = \"data/\"\n",
    "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Test Data Generation\n",
    "\n",
    "Generate synthetic evaluation data using Ragas knowledge graph approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/foohm/AIMakerSpace/AIE7/08_AdvancedBuild/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlineSplitter:   0%|          | 0/20 [00:00<?, ?it/s]           unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "Applying SummaryExtractor:  48%|████▊     | 15/31 [00:08<00:13,  1.15it/s]Property 'summary' already exists in node '5960f8'. Skipping!\n",
      "Applying SummaryExtractor:  52%|█████▏    | 16/31 [00:09<00:12,  1.20it/s]Property 'summary' already exists in node 'ae0774'. Skipping!\n",
      "Applying SummaryExtractor:  55%|█████▍    | 17/31 [00:10<00:11,  1.25it/s]Property 'summary' already exists in node '076ae4'. Skipping!\n",
      "Applying SummaryExtractor:  61%|██████▏   | 19/31 [00:14<00:15,  1.26s/it]Property 'summary' already exists in node '7e95f0'. Skipping!\n",
      "Applying SummaryExtractor:  68%|██████▊   | 21/31 [00:18<00:14,  1.46s/it]Property 'summary' already exists in node 'f22e47'. Skipping!\n",
      "Applying SummaryExtractor:  71%|███████   | 22/31 [00:19<00:10,  1.14s/it]Property 'summary' already exists in node '565677'. Skipping!\n",
      "Applying SummaryExtractor:  74%|███████▍  | 23/31 [00:25<00:21,  2.67s/it]Property 'summary' already exists in node 'f5691c'. Skipping!\n",
      "Applying SummaryExtractor:  77%|███████▋  | 24/31 [00:27<00:16,  2.35s/it]Property 'summary' already exists in node 'c46962'. Skipping!\n",
      "Applying SummaryExtractor:  81%|████████  | 25/31 [00:28<00:13,  2.20s/it]Property 'summary' already exists in node '7844de'. Skipping!\n",
      "Applying SummaryExtractor:  84%|████████▍ | 26/31 [00:29<00:08,  1.70s/it]Property 'summary' already exists in node '94497f'. Skipping!\n",
      "Applying SummaryExtractor:  87%|████████▋ | 27/31 [00:32<00:08,  2.15s/it]Property 'summary' already exists in node 'e96634'. Skipping!\n",
      "Applying SummaryExtractor:  90%|█████████ | 28/31 [00:33<00:05,  1.73s/it]Property 'summary' already exists in node '9ff5cd'. Skipping!\n",
      "Applying SummaryExtractor:  94%|█████████▎| 29/31 [00:37<00:04,  2.32s/it]Property 'summary' already exists in node '06b2a0'. Skipping!\n",
      "Property 'summary' already exists in node '2328fe'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   7%|▋         | 3/41 [00:00<00:05,  7.42it/s]Property 'summary_embedding' already exists in node 'f5691c'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  17%|█▋        | 7/41 [00:00<00:02, 15.36it/s]Property 'summary_embedding' already exists in node '565677'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '9ff5cd'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  39%|███▉      | 16/41 [00:00<00:00, 34.94it/s]Property 'summary_embedding' already exists in node '2328fe'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '076ae4'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '94497f'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  54%|█████▎    | 22/41 [00:00<00:00, 41.23it/s]Property 'summary_embedding' already exists in node '5960f8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '06b2a0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7844de'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ae0774'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'c46962'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  68%|██████▊   | 28/41 [00:00<00:00, 45.83it/s]Property 'summary_embedding' already exists in node 'e96634'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7e95f0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f22e47'. Skipping!\n",
      "Generating personas: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]                                           \n",
      "Generating Scenarios: 100%|██████████| 3/3 [00:31<00:00, 10.55s/it]\n",
      "Generating Samples: 100%|██████████| 12/12 [00:42<00:00,  3.54s/it]\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs[:20], testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the use of BBAY 3 affect Direct Loan ...</td>\n",
       "      <td>[non-term (includes clock-hour calendars), or ...</td>\n",
       "      <td>If substantially equal nonstandard terms in a ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a Financial Aid Administrator, how does the...</td>\n",
       "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
       "      <td>If required osteopathic clinical work meets al...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the Non-Term Characteristics that det...</td>\n",
       "      <td>[Non-Term Characteristics A program that measu...</td>\n",
       "      <td>A program is considered to have Non-Term Chara...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When must the annual loan limit for a Direct L...</td>\n",
       "      <td>[both the credit or clock hours and the weeks ...</td>\n",
       "      <td>If a student enrolled in a program that is gre...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the disbursement requirements for fed...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what is the disbursement requirements for fede...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>the disbursement requirements for federal stud...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the distinction between standard and n...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>The distinction between standard and nonstanda...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do the disbursement requirements for feder...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do the characteristics of non-term and sub...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nnon-term (includes clock-hour cale...</td>\n",
       "      <td>The characteristics of non-term and subscripti...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>According to Volume 8, Chapter 3, how do the d...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
       "      <td>Volume 8, Chapter 3 explains that in subscript...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>According to the guidance in Volume 2, Chapter...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>To determine whether clinical work in a medica...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>According to the guidance in Volume 1, Chapter...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
       "      <td>In subscription-based programs, as described i...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   How does the use of BBAY 3 affect Direct Loan ...   \n",
       "1   As a Financial Aid Administrator, how does the...   \n",
       "2   What are the Non-Term Characteristics that det...   \n",
       "3   When must the annual loan limit for a Direct L...   \n",
       "4   What are the disbursement requirements for fed...   \n",
       "5   what is the disbursement requirements for fede...   \n",
       "6   What is the distinction between standard and n...   \n",
       "7   How do the disbursement requirements for feder...   \n",
       "8   How do the characteristics of non-term and sub...   \n",
       "9   According to Volume 8, Chapter 3, how do the d...   \n",
       "10  According to the guidance in Volume 2, Chapter...   \n",
       "11  According to the guidance in Volume 1, Chapter...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [non-term (includes clock-hour calendars), or ...   \n",
       "1   [Inclusion of Clinical Work in a Standard Term...   \n",
       "2   [Non-Term Characteristics A program that measu...   \n",
       "3   [both the credit or clock hours and the weeks ...   \n",
       "4   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "5   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "6   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "7   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "8   [<1-hop>\\n\\nnon-term (includes clock-hour cale...   \n",
       "9   [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
       "10  [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "11  [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   If substantially equal nonstandard terms in a ...   \n",
       "1   If required osteopathic clinical work meets al...   \n",
       "2   A program is considered to have Non-Term Chara...   \n",
       "3   If a student enrolled in a program that is gre...   \n",
       "4   In clock-hour or non-term credit-hour programs...   \n",
       "5   the disbursement requirements for federal stud...   \n",
       "6   The distinction between standard and nonstanda...   \n",
       "7   In clock-hour or non-term credit-hour programs...   \n",
       "8   The characteristics of non-term and subscripti...   \n",
       "9   Volume 8, Chapter 3 explains that in subscript...   \n",
       "10  To determine whether clinical work in a medica...   \n",
       "11  In subscription-based programs, as described i...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline RAG Pipeline\n",
    "\n",
    "Build the baseline RAG using RecursiveCharacterTextSplitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents again for RAG pipeline\n",
    "path = \"data/\"\n",
    "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1102"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "len(split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"loan_data\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"loan_data\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = vector_store.add_documents(documents=split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    retrieved_docs = retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Prompt and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "You are a helpful assistant who answers questions based on provided context. You must only use the provided context, and cannot use your own knowledge.\n",
    "\n",
    "### Question\n",
    "{question}\n",
    "\n",
    "### Context\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = rag_prompt.format_messages(question=state[\"question\"], context=docs_content)\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"response\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the baseline pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, the different kinds of loans mentioned are:\\n\\n1. **Direct Loan**  \\n   - This includes loans that are associated with academic programs, where the type of academic year and program structure can influence the monitoring and eligibility. The Direct Loan can be either subsidized or unsubsidized, with the latter allowing interest to accrue during in-school periods if the borrower chooses to pay it.\\n\\n2. **Direct Unsubsidized Loan**  \\n   - A specific type of Direct Loan where interest accrues during periods when the borrower is in school, and there is an option to pay the interest while in school.\\n\\nThe context primarily discusses the structure and management of these loans rather than explicitly listing other types such as Stafford or PLUS loans, but it emphasizes the concept of direct loans, including unsubsidized varieties.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What are the different kinds of loans?\"})\n",
    "response[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Evaluation with Ragas\n",
    "\n",
    "Run the synthetic queries through the baseline pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_row in dataset:\n",
    "    response = graph.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "    test_row.eval_sample.response = response[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  99%|█████████▊| 71/72 [06:01<00:30, 30.39s/it]Exception raised in Job[53]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 72/72 [07:04<00:00,  5.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.7954, 'faithfulness': 0.9132, 'factual_correctness(mode=f1)': 0.6258, 'answer_relevancy': 0.9673, 'context_entity_recall': 0.3975, 'noise_sensitivity(mode=relevant)': 0.2987}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
    "from ragas import evaluate, RunConfig\n",
    "\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "baseline_result = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config\n",
    ")\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>factual_correctness(mode=f1)</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_entity_recall</th>\n",
       "      <th>noise_sensitivity(mode=relevant)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the use of BBAY 3 affect Direct Loan ...</td>\n",
       "      <td>[BBAY 3 for purposes of monitoring Direct Loan...</td>\n",
       "      <td>[non-term (includes clock-hour calendars), or ...</td>\n",
       "      <td>The use of BBAY 3 affects Direct Loan annual l...</td>\n",
       "      <td>If substantially equal nonstandard terms in a ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a Financial Aid Administrator, how does the...</td>\n",
       "      <td>[Credit hours associated with the practicum or...</td>\n",
       "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
       "      <td>As a Financial Aid Administrator, when a requi...</td>\n",
       "      <td>If required osteopathic clinical work meets al...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.954285</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the Non-Term Characteristics that det...</td>\n",
       "      <td>[Non-Term Characteristics\\nA program that meas...</td>\n",
       "      <td>[Non-Term Characteristics A program that measu...</td>\n",
       "      <td>The Non-Term Characteristics that determine if...</td>\n",
       "      <td>A program is considered to have Non-Term Chara...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When must the annual loan limit for a Direct L...</td>\n",
       "      <td>[information on Direct Loan annual loan limit ...</td>\n",
       "      <td>[both the credit or clock hours and the weeks ...</td>\n",
       "      <td>The annual loan limit for a Direct Loan must b...</td>\n",
       "      <td>If a student enrolled in a program that is gre...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the disbursement requirements for fed...</td>\n",
       "      <td>[Disbursement Timing in Subscription-Based Pro...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
       "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.960329</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what is the disbursement requirements for fede...</td>\n",
       "      <td>[Disbursement Timing in Subscription-Based Pro...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>The disbursement requirements for federal stud...</td>\n",
       "      <td>the disbursement requirements for federal stud...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.951837</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the distinction between standard and n...</td>\n",
       "      <td>[be offered in nonstandard terms. Also, like s...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>The distinction between standard and nonstanda...</td>\n",
       "      <td>The distinction between standard and nonstanda...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.920910</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do the disbursement requirements for feder...</td>\n",
       "      <td>[section below.\\nExcept as noted above for the...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>The disbursement requirements for federal stud...</td>\n",
       "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.987057</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do the characteristics of non-term and sub...</td>\n",
       "      <td>[use of a Scheduled Academic Year (SAY), BBAY ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nnon-term (includes clock-hour cale...</td>\n",
       "      <td>The characteristics of non-term and subscripti...</td>\n",
       "      <td>The characteristics of non-term and subscripti...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.966016</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>According to Volume 8, Chapter 3, how do the d...</td>\n",
       "      <td>[just one annual loan limit for the entire 110...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
       "      <td>According to Volume 8, Chapter 3, the disburse...</td>\n",
       "      <td>Volume 8, Chapter 3 explains that in subscript...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.951857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>According to the guidance in Volume 2, Chapter...</td>\n",
       "      <td>[Work in a Standard Term=). If a standard term...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>According to the guidance in Volume 2, Chapter...</td>\n",
       "      <td>To determine whether clinical work in a medica...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.956419</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>According to the guidance in Volume 1, Chapter...</td>\n",
       "      <td>[Disbursement Timing in Subscription-Based Pro...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
       "      <td>According to the guidance in Volume 1, Chapter...</td>\n",
       "      <td>In subscription-based programs, as described i...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.959264</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   How does the use of BBAY 3 affect Direct Loan ...   \n",
       "1   As a Financial Aid Administrator, how does the...   \n",
       "2   What are the Non-Term Characteristics that det...   \n",
       "3   When must the annual loan limit for a Direct L...   \n",
       "4   What are the disbursement requirements for fed...   \n",
       "5   what is the disbursement requirements for fede...   \n",
       "6   What is the distinction between standard and n...   \n",
       "7   How do the disbursement requirements for feder...   \n",
       "8   How do the characteristics of non-term and sub...   \n",
       "9   According to Volume 8, Chapter 3, how do the d...   \n",
       "10  According to the guidance in Volume 2, Chapter...   \n",
       "11  According to the guidance in Volume 1, Chapter...   \n",
       "\n",
       "                                   retrieved_contexts  \\\n",
       "0   [BBAY 3 for purposes of monitoring Direct Loan...   \n",
       "1   [Credit hours associated with the practicum or...   \n",
       "2   [Non-Term Characteristics\\nA program that meas...   \n",
       "3   [information on Direct Loan annual loan limit ...   \n",
       "4   [Disbursement Timing in Subscription-Based Pro...   \n",
       "5   [Disbursement Timing in Subscription-Based Pro...   \n",
       "6   [be offered in nonstandard terms. Also, like s...   \n",
       "7   [section below.\\nExcept as noted above for the...   \n",
       "8   [use of a Scheduled Academic Year (SAY), BBAY ...   \n",
       "9   [just one annual loan limit for the entire 110...   \n",
       "10  [Work in a Standard Term=). If a standard term...   \n",
       "11  [Disbursement Timing in Subscription-Based Pro...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [non-term (includes clock-hour calendars), or ...   \n",
       "1   [Inclusion of Clinical Work in a Standard Term...   \n",
       "2   [Non-Term Characteristics A program that measu...   \n",
       "3   [both the credit or clock hours and the weeks ...   \n",
       "4   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "5   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "6   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "7   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "8   [<1-hop>\\n\\nnon-term (includes clock-hour cale...   \n",
       "9   [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
       "10  [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "11  [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
       "\n",
       "                                             response  \\\n",
       "0   The use of BBAY 3 affects Direct Loan annual l...   \n",
       "1   As a Financial Aid Administrator, when a requi...   \n",
       "2   The Non-Term Characteristics that determine if...   \n",
       "3   The annual loan limit for a Direct Loan must b...   \n",
       "4   In clock-hour or non-term credit-hour programs...   \n",
       "5   The disbursement requirements for federal stud...   \n",
       "6   The distinction between standard and nonstanda...   \n",
       "7   The disbursement requirements for federal stud...   \n",
       "8   The characteristics of non-term and subscripti...   \n",
       "9   According to Volume 8, Chapter 3, the disburse...   \n",
       "10  According to the guidance in Volume 2, Chapter...   \n",
       "11  According to the guidance in Volume 1, Chapter...   \n",
       "\n",
       "                                            reference  context_recall  \\\n",
       "0   If substantially equal nonstandard terms in a ...        0.000000   \n",
       "1   If required osteopathic clinical work meets al...        1.000000   \n",
       "2   A program is considered to have Non-Term Chara...        1.000000   \n",
       "3   If a student enrolled in a program that is gre...        1.000000   \n",
       "4   In clock-hour or non-term credit-hour programs...        0.833333   \n",
       "5   the disbursement requirements for federal stud...        1.000000   \n",
       "6   The distinction between standard and nonstanda...        1.000000   \n",
       "7   In clock-hour or non-term credit-hour programs...        0.666667   \n",
       "8   The characteristics of non-term and subscripti...        0.777778   \n",
       "9   Volume 8, Chapter 3 explains that in subscript...        0.666667   \n",
       "10  To determine whether clinical work in a medica...        1.000000   \n",
       "11  In subscription-based programs, as described i...        0.600000   \n",
       "\n",
       "    faithfulness  factual_correctness(mode=f1)  answer_relevancy  \\\n",
       "0       0.857143                          0.33          0.999998   \n",
       "1       0.941176                          0.70          0.954285   \n",
       "2       1.000000                          0.83          1.000000   \n",
       "3       1.000000                          0.57          0.999999   \n",
       "4       1.000000                          0.84          0.960329   \n",
       "5       0.933333                          0.70          0.951837   \n",
       "6       1.000000                          0.63          0.920910   \n",
       "7       0.909091                          0.46          0.987057   \n",
       "8       0.692308                          0.61          0.966016   \n",
       "9       0.875000                          0.50          0.951857   \n",
       "10      0.833333                          0.67          0.956419   \n",
       "11      0.916667                          0.67          0.959264   \n",
       "\n",
       "    context_entity_recall  noise_sensitivity(mode=relevant)  \n",
       "0                1.000000                          0.000000  \n",
       "1                0.266667                          0.157895  \n",
       "2                0.444444                          0.888889  \n",
       "3                0.777778                          0.000000  \n",
       "4                0.222222                          0.000000  \n",
       "5                0.357143                          0.333333  \n",
       "6                0.444444                          0.375000  \n",
       "7                0.437500                          0.363636  \n",
       "8                0.578947                               NaN  \n",
       "9                0.000000                          0.500000  \n",
       "10               0.150000                          0.416667  \n",
       "11               0.090909                          0.250000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df = baseline_result.to_pandas()\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the TOCChunker\n",
    "\n",
    "Now we'll implement the same RAG pipeline but using semantic-based chunking with TOCChunker instead of RecursiveCharacterTextSplitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Additional Dependencies for TOCChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-core\n",
      "  Downloading llama_index_core-0.12.49-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-readers-file\n",
      "  Downloading llama_index_readers_file-0.4.11-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in ./venv/lib/python3.13/site-packages (from llama-index-core) (3.12.14)\n",
      "Collecting aiosqlite (from llama-index-core)\n",
      "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.0.0 (from llama-index-core)\n",
      "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib/python3.13/site-packages (from llama-index-core) (0.6.7)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.13/site-packages (from llama-index-core) (2025.3.0)\n",
      "Requirement already satisfied: httpx in ./venv/lib/python3.13/site-packages (from llama-index-core) (0.28.1)\n",
      "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core)\n",
      "  Downloading llama_index_workflows-1.1.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./venv/lib/python3.13/site-packages (from llama-index-core) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index-core)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (from llama-index-core) (2.3.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv/lib/python3.13/site-packages (from llama-index-core) (11.3.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in ./venv/lib/python3.13/site-packages (from llama-index-core) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in ./venv/lib/python3.13/site-packages (from llama-index-core) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv/lib/python3.13/site-packages (from llama-index-core) (2.32.4)\n",
      "Collecting setuptools>=80.9.0 (from llama-index-core)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./venv/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./venv/lib/python3.13/site-packages (from llama-index-core) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./venv/lib/python3.13/site-packages (from llama-index-core) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in ./venv/lib/python3.13/site-packages (from llama-index-core) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib/python3.13/site-packages (from llama-index-core) (4.14.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv/lib/python3.13/site-packages (from llama-index-core) (0.9.0)\n",
      "Collecting wrapt (from llama-index-core)\n",
      "  Downloading wrapt-1.17.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file)\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting defusedxml>=0.7.1 (from llama-index-readers-file)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting pandas<2.3.0 (from llama-index-readers-file)\n",
      "  Downloading pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file)\n",
      "  Downloading pypdf-5.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.20.1)\n",
      "Collecting griffe (from banks<3,>=2.0.0->llama-index-core)\n",
      "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting jinja2 (from banks<3,>=2.0.0->llama-index-core)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: platformdirs in ./venv/lib/python3.13/site-packages (from banks<3,>=2.0.0->llama-index-core) (4.3.8)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<2,>=1.0.1->llama-index-core)\n",
      "  Downloading llama_index_instrumentation-0.3.0-py3-none-any.whl.metadata (252 bytes)\n",
      "Collecting click (from nltk>3.8.1->llama-index-core)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index-core)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core) (2024.11.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas<2.3.0->llama-index-readers-file) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas<2.3.0->llama-index-readers-file) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas<2.3.0->llama-index-readers-file) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core) (2025.7.14)\n",
      "Collecting greenlet>=1 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core)\n",
      "  Downloading greenlet-3.2.3-cp313-cp313-macosx_11_0_universal2.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.13/site-packages (from typing-inspect>=0.8.0->llama-index-core) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.13/site-packages (from dataclasses-json->llama-index-core) (3.26.1)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx->llama-index-core) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx->llama-index-core) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx->llama-index-core) (0.16.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.13/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (25.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx->llama-index-core) (1.3.1)\n",
      "Collecting colorama>=0.4 (from griffe->banks<3,>=2.0.0->llama-index-core)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->banks<3,>=2.0.0->llama-index-core)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Downloading llama_index_core-0.12.49-py3-none-any.whl (10.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_readers_file-0.4.11-py3-none-any.whl (41 kB)\n",
      "Downloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_index_workflows-1.1.0-py3-none-any.whl (37 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-5.8.0-py3-none-any.whl (309 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading wrapt-1.17.2-cp313-cp313-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Downloading greenlet-3.2.3-cp313-cp313-macosx_11_0_universal2.whl (270 kB)\n",
      "Downloading llama_index_instrumentation-0.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, wrapt, soupsieve, setuptools, pypdf, networkx, MarkupSafe, joblib, greenlet, defusedxml, colorama, click, aiosqlite, pandas, nltk, jinja2, griffe, deprecated, beautifulsoup4, llama-index-instrumentation, banks, llama-index-workflows, llama-index-core, llama-index-readers-file\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.3.1\n",
      "    Uninstalling pandas-2.3.1:\n",
      "      Successfully uninstalled pandas-2.3.1\n",
      "Successfully installed MarkupSafe-3.0.2 aiosqlite-0.21.0 banks-2.2.0 beautifulsoup4-4.13.4 click-8.2.1 colorama-0.4.6 defusedxml-0.7.1 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 greenlet-3.2.3 griffe-1.7.3 jinja2-3.1.6 joblib-1.5.1 llama-index-core-0.12.49 llama-index-instrumentation-0.3.0 llama-index-readers-file-0.4.11 llama-index-workflows-1.1.0 networkx-3.5 nltk-3.9.1 pandas-2.2.3 pypdf-5.8.0 setuptools-80.9.0 soupsieve-2.7 striprtf-0.0.26 wrapt-1.17.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-core llama-index-readers-file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Processing for TOCChunker\n",
    "\n",
    "Convert LangChain documents to format compatible with TOCChunker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 269 documents to LlamaIndex format\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document as LlamaDocument\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.extractors import TitleExtractor\n",
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "from llama_index.core.node_parser import get_leaf_nodes\n",
    "\n",
    "# Convert LangChain documents to LlamaIndex format\n",
    "llama_docs = []\n",
    "for doc in docs:\n",
    "    llama_doc = LlamaDocument(\n",
    "        text=doc.page_content,\n",
    "        metadata=doc.metadata\n",
    "    )\n",
    "    llama_docs.append(llama_doc)\n",
    "\n",
    "print(f\"Converted {len(llama_docs)} documents to LlamaIndex format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement TOCChunker Approach\n",
    "\n",
    "Create hierarchical chunks using LlamaIndex's HierarchicalNodeParser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 698 semantic chunks using hierarchical parsing\n"
     ]
    }
   ],
   "source": [
    "# Create hierarchical node parser (similar to TOCChunker approach)\n",
    "node_parser = HierarchicalNodeParser.from_defaults(\n",
    "    chunk_sizes=[2048, 1024, 512],  # Different levels of chunking\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "# Parse documents into hierarchical nodes\n",
    "nodes = node_parser.get_nodes_from_documents(llama_docs)\n",
    "\n",
    "# Get leaf nodes (finest level chunks)\n",
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "print(f\"Created {len(leaf_nodes)} semantic chunks using hierarchical parsing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Back to LangChain Format\n",
    "\n",
    "Convert the semantic chunks back to LangChain Document format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 698 semantic chunks to LangChain format\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document as LangChainDocument\n",
    "\n",
    "# Convert LlamaIndex nodes back to LangChain documents\n",
    "semantic_documents = []\n",
    "for node in leaf_nodes:\n",
    "    doc = LangChainDocument(\n",
    "        page_content=node.text,\n",
    "        metadata=node.metadata\n",
    "    )\n",
    "    semantic_documents.append(doc)\n",
    "\n",
    "print(f\"Converted {len(semantic_documents)} semantic chunks to LangChain format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New Vector Store for TOCChunker\n",
    "\n",
    "Build a new QDrant vector store with the semantic chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new QDrant client and collection for semantic chunks\n",
    "semantic_client = QdrantClient(\":memory:\")\n",
    "\n",
    "semantic_client.create_collection(\n",
    "    collection_name=\"loan_data_semantic\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "semantic_vector_store = QdrantVectorStore(\n",
    "    client=semantic_client,\n",
    "    collection_name=\"loan_data_semantic\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add semantic documents to the vector store\n",
    "_ = semantic_vector_store.add_documents(documents=semantic_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever for semantic chunks\n",
    "semantic_retriever = semantic_vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Semantic RAG Pipeline\n",
    "\n",
    "Create the same pipeline structure but with semantic retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_semantic(state):\n",
    "    retrieved_docs = semantic_retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticState(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    response: str\n",
    "\n",
    "semantic_graph_builder = StateGraph(SemanticState).add_sequence([retrieve_semantic, generate])\n",
    "semantic_graph_builder.add_edge(START, \"retrieve_semantic\")\n",
    "semantic_graph = semantic_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the semantic pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The different kinds of loans mentioned in the provided context include:\\n\\n1. **Direct Loans**\\n   - Subsidized Loans\\n   - Unsubsidized Loans\\n   - PLUS Loans (including Direct PLUS Loans)\\n\\n2. **Federal and Non-Federal Loans**\\n   - Federal Direct Loans (subcategories above)\\n   - Private Loans\\n   - State-sponsored Loans\\n   - Institutional Loans\\n\\n3. **Loans used to replace certain education-related benefits**\\n   - Education savings accounts such as TEACH Grants and AmeriCorps education awards\\n   - Foster care benefits received under Title IV, Part E, of the Social Security Act, including education and training vouchers and room and board benefits\\n   - Emergency financial assistance (such as emergency grants or short-term loans)\\n\\n4. **Private Education Loans**\\n   - Including income share agreements (ISAs) used to finance postsecondary education expenses, which are considered private education loans.\\n\\nThese cover various federal and private financing options available to students based on different circumstances and programs.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_response = semantic_graph.invoke({\"question\": \"What are the different kinds of loans?\"})\n",
    "semantic_response[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate TOCChunker Approach\n",
    "\n",
    "Run the same evaluation using the semantic chunking approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "# Create a copy of the dataset for semantic evaluation\n",
    "semantic_dataset = copy.deepcopy(dataset)\n",
    "\n",
    "# Run queries through the semantic pipeline\n",
    "for test_row in semantic_dataset:\n",
    "    response = semantic_graph.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "    test_row.eval_sample.response = response[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
    "    time.sleep(1)  # Rate limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_evaluation_dataset = EvaluationDataset.from_pandas(semantic_dataset.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "semantic_result"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  99%|█████████▊| 71/72 [05:27<00:19, 19.56s/it]Exception raised in Job[53]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 72/72 [07:02<00:00,  5.87s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.8972, 'faithfulness': 0.9341, 'factual_correctness(mode=f1)': 0.5933, 'answer_relevancy': 0.9653, 'context_entity_recall': 0.3332, 'noise_sensitivity(mode=relevant)': 0.2934}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_result = evaluate(\n",
    "    dataset=semantic_evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config\n",
    ")\n",
    "semantic_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>factual_correctness(mode=f1)</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_entity_recall</th>\n",
       "      <th>noise_sensitivity(mode=relevant)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the use of BBAY 3 affect Direct Loan ...</td>\n",
       "      <td>[regains eligibility for a new annual loan lim...</td>\n",
       "      <td>[non-term (includes clock-hour calendars), or ...</td>\n",
       "      <td>The use of BBAY 3 affects Direct Loan annual l...</td>\n",
       "      <td>If substantially equal nonstandard terms in a ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a Financial Aid Administrator, how does the...</td>\n",
       "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
       "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
       "      <td>As a Financial Aid Administrator, the inclusio...</td>\n",
       "      <td>If required osteopathic clinical work meets al...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.959953</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the Non-Term Characteristics that det...</td>\n",
       "      <td>[Nonstandard Terms\\nGenerally, nonstandard ter...</td>\n",
       "      <td>[Non-Term Characteristics A program that measu...</td>\n",
       "      <td>The Non-Term Characteristics that determine if...</td>\n",
       "      <td>A program is considered to have Non-Term Chara...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When must the annual loan limit for a Direct L...</td>\n",
       "      <td>[Specifically, if a student enrolled in a prog...</td>\n",
       "      <td>[both the credit or clock hours and the weeks ...</td>\n",
       "      <td>The annual loan limit for a Direct Loan must b...</td>\n",
       "      <td>If a student enrolled in a program that is gre...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the disbursement requirements for fed...</td>\n",
       "      <td>[Except as noted above for the Direct Loan Pro...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
       "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.958516</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what is the disbursement requirements for fede...</td>\n",
       "      <td>[Disbursement Timing in Subscription-Based Pro...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>The disbursement requirements for federal stud...</td>\n",
       "      <td>the disbursement requirements for federal stud...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.952477</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the distinction between standard and n...</td>\n",
       "      <td>[Nonstandard Terms\\nGenerally, nonstandard ter...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>The distinction between standard and nonstanda...</td>\n",
       "      <td>The distinction between standard and nonstanda...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.926679</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do the disbursement requirements for feder...</td>\n",
       "      <td>[Except as noted above for the Direct Loan Pro...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>The disbursement requirements differ between c...</td>\n",
       "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.967309</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do the characteristics of non-term and sub...</td>\n",
       "      <td>[Substantially\\nequal nonstandard terms may be...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nnon-term (includes clock-hour cale...</td>\n",
       "      <td>The characteristics of non-term and subscripti...</td>\n",
       "      <td>The characteristics of non-term and subscripti...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.966189</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>According to Volume 8, Chapter 3, how do the d...</td>\n",
       "      <td>[For example, a school might offer an\\n1100 cl...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
       "      <td>According to Volume 8, Chapter 3, the disburse...</td>\n",
       "      <td>Volume 8, Chapter 3 explains that in subscript...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.953025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>According to the guidance in Volume 2, Chapter...</td>\n",
       "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>According to the guidance in Volume 2, Chapter...</td>\n",
       "      <td>To determine whether clinical work in a medica...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.975462</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>According to the guidance in Volume 1, Chapter...</td>\n",
       "      <td>[Disbursement Timing in Subscription-Based Pro...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
       "      <td>In standard term-based programs, disbursement ...</td>\n",
       "      <td>In subscription-based programs, as described i...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.924104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   How does the use of BBAY 3 affect Direct Loan ...   \n",
       "1   As a Financial Aid Administrator, how does the...   \n",
       "2   What are the Non-Term Characteristics that det...   \n",
       "3   When must the annual loan limit for a Direct L...   \n",
       "4   What are the disbursement requirements for fed...   \n",
       "5   what is the disbursement requirements for fede...   \n",
       "6   What is the distinction between standard and n...   \n",
       "7   How do the disbursement requirements for feder...   \n",
       "8   How do the characteristics of non-term and sub...   \n",
       "9   According to Volume 8, Chapter 3, how do the d...   \n",
       "10  According to the guidance in Volume 2, Chapter...   \n",
       "11  According to the guidance in Volume 1, Chapter...   \n",
       "\n",
       "                                   retrieved_contexts  \\\n",
       "0   [regains eligibility for a new annual loan lim...   \n",
       "1   [Inclusion of Clinical Work in a Standard Term...   \n",
       "2   [Nonstandard Terms\\nGenerally, nonstandard ter...   \n",
       "3   [Specifically, if a student enrolled in a prog...   \n",
       "4   [Except as noted above for the Direct Loan Pro...   \n",
       "5   [Disbursement Timing in Subscription-Based Pro...   \n",
       "6   [Nonstandard Terms\\nGenerally, nonstandard ter...   \n",
       "7   [Except as noted above for the Direct Loan Pro...   \n",
       "8   [Substantially\\nequal nonstandard terms may be...   \n",
       "9   [For example, a school might offer an\\n1100 cl...   \n",
       "10  [Inclusion of Clinical Work in a Standard Term...   \n",
       "11  [Disbursement Timing in Subscription-Based Pro...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [non-term (includes clock-hour calendars), or ...   \n",
       "1   [Inclusion of Clinical Work in a Standard Term...   \n",
       "2   [Non-Term Characteristics A program that measu...   \n",
       "3   [both the credit or clock hours and the weeks ...   \n",
       "4   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "5   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "6   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "7   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "8   [<1-hop>\\n\\nnon-term (includes clock-hour cale...   \n",
       "9   [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
       "10  [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "11  [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
       "\n",
       "                                             response  \\\n",
       "0   The use of BBAY 3 affects Direct Loan annual l...   \n",
       "1   As a Financial Aid Administrator, the inclusio...   \n",
       "2   The Non-Term Characteristics that determine if...   \n",
       "3   The annual loan limit for a Direct Loan must b...   \n",
       "4   In clock-hour or non-term credit-hour programs...   \n",
       "5   The disbursement requirements for federal stud...   \n",
       "6   The distinction between standard and nonstanda...   \n",
       "7   The disbursement requirements differ between c...   \n",
       "8   The characteristics of non-term and subscripti...   \n",
       "9   According to Volume 8, Chapter 3, the disburse...   \n",
       "10  According to the guidance in Volume 2, Chapter...   \n",
       "11  In standard term-based programs, disbursement ...   \n",
       "\n",
       "                                            reference  context_recall  \\\n",
       "0   If substantially equal nonstandard terms in a ...        1.000000   \n",
       "1   If required osteopathic clinical work meets al...        1.000000   \n",
       "2   A program is considered to have Non-Term Chara...        1.000000   \n",
       "3   If a student enrolled in a program that is gre...        1.000000   \n",
       "4   In clock-hour or non-term credit-hour programs...        0.833333   \n",
       "5   the disbursement requirements for federal stud...        1.000000   \n",
       "6   The distinction between standard and nonstanda...        1.000000   \n",
       "7   In clock-hour or non-term credit-hour programs...        0.666667   \n",
       "8   The characteristics of non-term and subscripti...        1.000000   \n",
       "9   Volume 8, Chapter 3 explains that in subscript...        0.666667   \n",
       "10  To determine whether clinical work in a medica...        1.000000   \n",
       "11  In subscription-based programs, as described i...        0.600000   \n",
       "\n",
       "    faithfulness  factual_correctness(mode=f1)  answer_relevancy  \\\n",
       "0       0.857143                          0.22          0.999998   \n",
       "1       1.000000                          0.60          0.959953   \n",
       "2       0.857143                          0.29          1.000000   \n",
       "3       1.000000                          0.80          1.000000   \n",
       "4       1.000000                          0.71          0.958516   \n",
       "5       0.933333                          0.70          0.952477   \n",
       "6       1.000000                          0.64          0.926679   \n",
       "7       1.000000                          0.67          0.967309   \n",
       "8       0.911765                          0.70          0.966189   \n",
       "9       0.727273                          0.57          0.953025   \n",
       "10      1.000000                          0.55          0.975462   \n",
       "11      0.923077                          0.67          0.924104   \n",
       "\n",
       "    context_entity_recall  noise_sensitivity(mode=relevant)  \n",
       "0                0.500000                          0.000000  \n",
       "1                0.266667                          0.428571  \n",
       "2                0.333333                          0.285714  \n",
       "3                0.444444                          0.250000  \n",
       "4                0.375000                          0.294118  \n",
       "5                0.428571                          0.375000  \n",
       "6                0.550000                          0.285714  \n",
       "7                0.350000                          0.227273  \n",
       "8                0.500000                               NaN  \n",
       "9                0.000000                          0.600000  \n",
       "10               0.250000                          0.250000  \n",
       "11               0.000000                          0.230769  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_df = semantic_result.to_pandas()\n",
    "semantic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Compare the results between baseline RecursiveCharacterTextSplitter and semantic TOCChunker approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>factual_correctness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_entity_recall</th>\n",
       "      <th>noise_sensitivity_relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (RecursiveCharacterTextSplitter)</td>\n",
       "      <td>0.795370</td>\n",
       "      <td>0.913171</td>\n",
       "      <td>0.625833</td>\n",
       "      <td>0.967331</td>\n",
       "      <td>0.397505</td>\n",
       "      <td>0.298675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semantic (TOCChunker)</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.934144</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.965309</td>\n",
       "      <td>0.333168</td>\n",
       "      <td>0.293378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    approach  context_recall  faithfulness  \\\n",
       "0  Baseline (RecursiveCharacterTextSplitter)        0.795370      0.913171   \n",
       "1                      Semantic (TOCChunker)        0.897222      0.934144   \n",
       "\n",
       "   factual_correctness  answer_relevancy  context_entity_recall  \\\n",
       "0             0.625833          0.967331               0.397505   \n",
       "1             0.593333          0.965309               0.333168   \n",
       "\n",
       "   noise_sensitivity_relevant  \n",
       "0                    0.298675  \n",
       "1                    0.293378  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract metric averages\n",
    "baseline_metrics = {\n",
    "    'approach': 'Baseline (RecursiveCharacterTextSplitter)',\n",
    "    'context_recall': baseline_df['context_recall'].mean(),\n",
    "    'faithfulness': baseline_df['faithfulness'].mean(),\n",
    "    'factual_correctness': baseline_df['factual_correctness(mode=f1)'].mean(),\n",
    "    'answer_relevancy': baseline_df['answer_relevancy'].mean(),\n",
    "    'context_entity_recall': baseline_df['context_entity_recall'].mean(),\n",
    "    'noise_sensitivity_relevant': baseline_df['noise_sensitivity(mode=relevant)'].mean()\n",
    "}\n",
    "\n",
    "semantic_metrics = {\n",
    "    'approach': 'Semantic (TOCChunker)',\n",
    "    'context_recall': semantic_df['context_recall'].mean(),\n",
    "    'faithfulness': semantic_df['faithfulness'].mean(),\n",
    "    'factual_correctness': semantic_df['factual_correctness(mode=f1)'].mean(),\n",
    "    'answer_relevancy': semantic_df['answer_relevancy'].mean(),\n",
    "    'context_entity_recall': semantic_df['context_entity_recall'].mean(),\n",
    "    'noise_sensitivity_relevant': semantic_df['noise_sensitivity(mode=relevant)'].mean()\n",
    "}\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame([baseline_metrics, semantic_metrics])\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The comparison shows the performance differences between:\n",
    "\n",
    "1. **Baseline Approach**: Uses RecursiveCharacterTextSplitter with fixed chunk sizes (1000 characters, 200 overlap)\n",
    "2. **Semantic Approach**: Uses hierarchical parsing to create semantically meaningful chunks\n",
    "\n",
    "Key metrics to focus on:\n",
    "- **Answer Relevancy**: How relevant the generated answers are to the questions\n",
    "- **Faithfulness**: How well the answers stick to the provided context\n",
    "- **Context Recall**: How well the retrieval captures relevant information\n",
    "\n",
    "The semantic chunking approach aims to preserve document structure and meaning, potentially leading to better context coherence and improved retrieval performance.\n",
    "\n",
    "##### Conclusion\n",
    "Overall what it looks like is there is a significant improvement in `context_recall` as for the rest of the metrics there is small improvement for `faithfulness` and small deterioration in the others although it could be argued tha amount is not significant (< 10%). It does point to this approach to chunking (or how it was implemented) while seemingly getting us better retrieval metrics, did not move the needle for the more important metric of `answer_relevancy` as opposed to reranking where we use a model (Cohere's) trained on Q&A data to help us rank the chunks. My intuition is that the key reason is that while we are pulling more chunks that are **semantically similar** they may not be as **relevant** to the query.     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
