{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent LangGraph System for Research Paper Social Media Posts\n",
    "\n",
    "This notebook implements a multi-agent LangGraph system that takes a research paper description and creates social media posts optimized for different platforms.\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "The system consists of 4 main agents:\n",
    "1. **SEARCH_AGENT**: Searches arXiv for research papers and extracts content\n",
    "2. **SOCIAL_MEDIA_AGENT**: Creates social media posts from paper content\n",
    "3. **COPY_EDITOR**: Refines posts to fit the target platform's tone\n",
    "4. **SUPERVISOR**: Coordinates workflow between agents\n",
    "\n",
    "## Input Parameters\n",
    "- Research paper description\n",
    "- Target social network (LinkedIn, X, Facebook)\n",
    "- Objective of the social media post\n",
    "\n",
    "## Output\n",
    "- Social media post saved as markdown text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies\n",
    "\n",
    "First, we'll set up our environment variables and import all necessary libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, install the required Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.13/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-openai in ./venv/lib/python3.13/site-packages (0.3.28)\n",
      "Requirement already satisfied: langchain-community in ./venv/lib/python3.13/site-packages (0.3.27)\n",
      "Requirement already satisfied: langgraph in ./venv/lib/python3.13/site-packages (0.5.2)\n",
      "Requirement already satisfied: langsmith in ./venv/lib/python3.13/site-packages (0.4.5)\n",
      "Collecting arxiv\n",
      "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.68)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in ./venv/lib/python3.13/site-packages (from langchain-openai) (1.95.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./venv/lib/python3.13/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.13/site-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.3.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in ./venv/lib/python3.13/site-packages (from langgraph) (2.1.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in ./venv/lib/python3.13/site-packages (from langgraph) (0.5.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in ./venv/lib/python3.13/site-packages (from langgraph) (0.1.72)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./venv/lib/python3.13/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith) (3.10.18)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.13/site-packages (from langsmith) (24.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith) (0.23.0)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./venv/lib/python3.13/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=944dbd62340e514ade3e6bbee83a36aa0a1b3c8d0b5766722792421aedce4633\n",
      "  Stored in directory: /Users/foohm/Library/Caches/pip/wheels/3d/4d/ef/37cdccc18d6fd7e0dd7817dcdf9146d4d6789c32a227a28134\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "Successfully installed arxiv-2.2.0 feedparser-6.0.11 sgmllib3k-1.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai langchain-community langgraph langsmith arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from uuid import uuid4\n",
    "from typing import TypedDict, Annotated, List\n",
    "from pathlib import Path\n",
    "import operator\n",
    "import functools\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Configuration\n",
    "\n",
    "Set up LangSmith tracing for monitoring and debugging our multi-agent system.\n",
    "\n",
    "**LangSmith Setup Instructions:**\n",
    "1. Go to [LangSmith](https://smith.langchain.com/) and create an account\n",
    "2. Create a new project or use an existing one\n",
    "3. Navigate to Settings ‚Üí API Keys\n",
    "4. Create a new API key and copy it\n",
    "5. Enter the API key when prompted below\n",
    "\n",
    "LangSmith will automatically trace all agent interactions, tool usage, and workflow execution, providing valuable insights into your multi-agent system's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LangSmith tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE7 - Research Paper Social Media - {uuid4().hex[0:8]}\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Directory Setup\n",
    "\n",
    "Create a directory for file operations where our agents will save and read files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/foohm/AIMakerSpace/AIE7/06_BonusAssignment/output\n"
     ]
    }
   ],
   "source": [
    "# Working directory for file operations\n",
    "WORKING_DIRECTORY = Path(\"./output\")\n",
    "WORKING_DIRECTORY.mkdir(exist_ok=True)\n",
    "print(f\"Working directory: {WORKING_DIRECTORY.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Definition\n",
    "\n",
    "Define the state that will be passed between agents. This includes the conversation history, paper content, target platform, and workflow control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchPaperSocialMediaState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    paper_text: str\n",
    "    social_network: str\n",
    "    objective: str\n",
    "    social_media_post: str\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Management Tools\n",
    "\n",
    "Create tools for reading, writing, and editing files. These will be used by our agents to manage paper content and social media posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def file_read(file_path: str) -> str:\n",
    "    \"\"\"Read a text file and return its contents as a string.\"\"\"\n",
    "    try:\n",
    "        with open(WORKING_DIRECTORY / file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        return f\"File {file_path} not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def file_write(content: str, file_path: str) -> str:\n",
    "    \"\"\"Write content to a text file.\"\"\"\n",
    "    try:\n",
    "        with open(WORKING_DIRECTORY / file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        return f\"Content successfully written to {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing to file: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def file_edit(file_path: str, line_number: int, new_content: str) -> str:\n",
    "    \"\"\"Insert content at a specific line in a text file.\"\"\"\n",
    "    try:\n",
    "        with open(WORKING_DIRECTORY / file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        if line_number < 1 or line_number > len(lines) + 1:\n",
    "            return f\"Line number {line_number} is out of range.\"\n",
    "        \n",
    "        lines.insert(line_number - 1, new_content + '\\n')\n",
    "        \n",
    "        with open(WORKING_DIRECTORY / file_path, 'w', encoding='utf-8') as f:\n",
    "            f.writelines(lines)\n",
    "        \n",
    "        return f\"Content inserted at line {line_number} in {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error editing file: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Create helper functions for agent creation and workflow management, following the patterns from the reference notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str) -> AgentExecutor:\n",
    "    \"\"\"Create a function-calling agent with tools.\"\"\"\n",
    "    system_prompt += (\"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
    "                     \" Do not ask for clarification.\"\n",
    "                     \" Your other team members will collaborate with you with their own specialties.\"\n",
    "                     \" You are chosen for a reason!\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    \n",
    "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    \"\"\"Execute an agent and return the result as a message.\"\"\"\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "def create_supervisor(llm: ChatOpenAI, system_prompt: str, members: List[str]) -> callable:\n",
    "    \"\"\"Create a supervisor agent that routes to team members.\"\"\"\n",
    "    options = [\"FINISH\"] + members\n",
    "    function_def = {\n",
    "        \"name\": \"route\",\n",
    "        \"description\": \"Select the next role.\",\n",
    "        \"parameters\": {\n",
    "            \"title\": \"routeSchema\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"next\": {\n",
    "                    \"title\": \"Next\",\n",
    "                    \"anyOf\": [{\"enum\": options}],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"next\"],\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"system\", \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "    ]).partial(options=str(options), team_members=\", \".join(members))\n",
    "    \n",
    "    return (\n",
    "        prompt\n",
    "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "        | JsonOutputFunctionsParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Language Model and Tools\n",
    "\n",
    "Set up the language model and arXiv search tool that will be used across our agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language model and tools initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Initialize the arXiv search tool\n",
    "arxiv_tool = ArxivQueryRun()\n",
    "\n",
    "print(\"Language model and tools initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Creation\n",
    "\n",
    "Create our four specialized agents, each with specific tools and responsibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Agent\n",
    "\n",
    "The Search Agent uses the arXiv tool to find research papers and save their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "search_agent = create_agent(\n",
    "    llm,\n",
    "    [arxiv_tool, file_write],\n",
    "    (\"You are a research assistant specialized in finding academic papers on arXiv. \"\n",
    "     \"When given a description of a paper, search for it using the arXiv tool and \"\n",
    "     \"extract the full text content. Save the paper content to a file called 'paper_content.txt' for later use. \"\n",
    "     \"Focus on finding the most relevant and recent papers. If you find multiple papers, \"\n",
    "     \"choose the most relevant one based on the description provided.\")\n",
    ")\n",
    "\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"SEARCH_AGENT\")\n",
    "print(\"Search Agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Media Agent\n",
    "\n",
    "The Social Media Agent reads research papers and creates engaging social media posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social Media Agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "social_media_agent = create_agent(\n",
    "    llm,\n",
    "    [file_read, file_write],\n",
    "    (\"You are a social media content creator specialized in translating complex academic \"\n",
    "     \"research into engaging social media posts. You understand how to adapt content for \"\n",
    "     \"different platforms (LinkedIn, X/Twitter, Facebook) and create posts that match the \"\n",
    "     \"target objective. Read the research paper content from 'paper_content.txt' and create \"\n",
    "     \"compelling social media posts. Save your post to 'social_media_post.txt'. \"\n",
    "     \"Consider the target social network and objective when crafting your post. \"\n",
    "     \"Make it engaging, informative, and appropriate for the platform.\")\n",
    ")\n",
    "\n",
    "social_media_node = functools.partial(agent_node, agent=social_media_agent, name=\"SOCIAL_MEDIA_AGENT\")\n",
    "print(\"Social Media Agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Editor Agent\n",
    "\n",
    "The Copy Editor Agent refines social media posts to ensure they fit the target platform's tone and style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy Editor Agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "copy_editor = create_agent(\n",
    "    llm,\n",
    "    [file_read, file_write, file_edit],\n",
    "    (\"You are an expert copy editor specializing in social media content. Your role is to \"\n",
    "     \"review and refine social media posts to ensure they fit the tone and style of the \"\n",
    "     \"specified social network. Read the social media post from 'social_media_post.txt' \"\n",
    "     \"and edit it to make sure it's engaging, grammatically correct, and appropriate for \"\n",
    "     \"the target platform and audience. Consider platform-specific best practices: \"\n",
    "     \"LinkedIn (professional, informative), X (concise, engaging), Facebook (conversational, accessible). \"\n",
    "     \"Save the final edited post to 'final_social_media_post.md' with markdown formatting.\")\n",
    ")\n",
    "\n",
    "copy_editor_node = functools.partial(agent_node, agent=copy_editor, name=\"COPY_EDITOR\")\n",
    "print(\"Copy Editor Agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervisor Agent\n",
    "\n",
    "The Supervisor Agent coordinates the workflow between all agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervisor Agent created successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/11/l5r6prl962nbqt1wkfxvltm40000gn/T/ipykernel_5651/2020880168.py:50: LangChainDeprecationWarning: The method `BaseChatOpenAI.bind_functions` was deprecated in langchain-openai 0.2.1 and will be removed in 1.0.0. Use :meth:`~langchain_openai.chat_models.base.ChatOpenAI.bind_tools` instead.\n",
      "  | llm.bind_functions(functions=[function_def], function_call=\"route\")\n"
     ]
    }
   ],
   "source": [
    "supervisor = create_supervisor(\n",
    "    llm,\n",
    "    (\"You are a supervisor coordinating a team to create social media posts from research papers. \"\n",
    "     \"The team consists of: SEARCH_AGENT (finds papers), SOCIAL_MEDIA_AGENT (creates posts), \"\n",
    "     \"and COPY_EDITOR (refines posts). Guide the workflow in this order: \"\n",
    "     \"1. First, use SEARCH_AGENT to find and save the research paper content \"\n",
    "     \"2. Then, use SOCIAL_MEDIA_AGENT to create a social media post from the paper \"\n",
    "     \"3. Finally, use COPY_EDITOR to refine the post for the target platform \"\n",
    "     \"When the final post is ready and saved, respond with FINISH.\"),\n",
    "    [\"SEARCH_AGENT\", \"SOCIAL_MEDIA_AGENT\", \"COPY_EDITOR\"]\n",
    ")\n",
    "\n",
    "print(\"Supervisor Agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Construction\n",
    "\n",
    "Build the LangGraph workflow by connecting all agents and defining the flow logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph workflow compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create the state graph\n",
    "workflow = StateGraph(ResearchPaperSocialMediaState)\n",
    "\n",
    "# Add nodes for each agent\n",
    "workflow.add_node(\"SEARCH_AGENT\", search_node)\n",
    "workflow.add_node(\"SOCIAL_MEDIA_AGENT\", social_media_node)\n",
    "workflow.add_node(\"COPY_EDITOR\", copy_editor_node)\n",
    "workflow.add_node(\"supervisor\", supervisor)\n",
    "\n",
    "# Add edges from agents back to supervisor\n",
    "workflow.add_edge(\"SEARCH_AGENT\", \"supervisor\")\n",
    "workflow.add_edge(\"SOCIAL_MEDIA_AGENT\", \"supervisor\")\n",
    "workflow.add_edge(\"COPY_EDITOR\", \"supervisor\")\n",
    "\n",
    "# Add conditional edges from supervisor to agents\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"SEARCH_AGENT\": \"SEARCH_AGENT\",\n",
    "        \"SOCIAL_MEDIA_AGENT\": \"SOCIAL_MEDIA_AGENT\",\n",
    "        \"COPY_EDITOR\": \"COPY_EDITOR\",\n",
    "        \"FINISH\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Set supervisor as entry point\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = workflow.compile()\n",
    "\n",
    "print(\"LangGraph workflow compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Execution Function\n",
    "\n",
    "Create a function to execute the multi-agent system with the required parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_social_media_post(paper_description: str, social_network: str, objective: str):\n",
    "    \"\"\"\n",
    "    Create a social media post from a research paper.\n",
    "    \n",
    "    Args:\n",
    "        paper_description: Description of the research paper to search for\n",
    "        social_network: Target social network (LinkedIn, X, Facebook)\n",
    "        objective: The objective/goal of the social media post\n",
    "    \"\"\"\n",
    "    initial_message = (\n",
    "        f\"Create a social media post for {social_network} about the research paper: {paper_description}. \"\n",
    "        f\"The objective is: {objective}. \"\n",
    "        f\"First, search for and retrieve the paper content, then create an engaging post, \"\n",
    "        f\"and finally edit it to fit the {social_network} platform style.\"\n",
    "    )\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=initial_message)],\n",
    "        \"paper_text\": \"\",\n",
    "        \"social_network\": social_network,\n",
    "        \"objective\": objective,\n",
    "        \"social_media_post\": \"\",\n",
    "        \"next\": \"\"\n",
    "    }\n",
    "    \n",
    "    print(f\"üöÄ Starting social media post creation for {social_network}...\")\n",
    "    print(f\"üìÑ Paper: {paper_description}\")\n",
    "    print(f\"üéØ Objective: {objective}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Stream the workflow execution\n",
    "    for step in graph.stream(initial_state, {\"recursion_limit\": 20}):\n",
    "        if \"__end__\" not in step:\n",
    "            for node_name, node_output in step.items():\n",
    "                print(f\"ü§ñ [{node_name}] Output:\")\n",
    "                if \"messages\" in node_output:\n",
    "                    print(node_output[\"messages\"][-1].content)\n",
    "                elif \"next\" in node_output:\n",
    "                    print(f\"‚û°Ô∏è Next: {node_output['next']}\")\n",
    "                print(\"-\" * 50)\n",
    "    \n",
    "    print(\"‚úÖ Social media post creation completed!\")\n",
    "    \n",
    "    # Check for output files and display final result\n",
    "    output_files = list(WORKING_DIRECTORY.glob(\"*.md\"))\n",
    "    if not output_files:\n",
    "        output_files = list(WORKING_DIRECTORY.glob(\"*.txt\"))\n",
    "    \n",
    "    if output_files:\n",
    "        print(f\"üìÅ Output files created: {[f.name for f in output_files]}\")\n",
    "        \n",
    "        # Find the final post file\n",
    "        final_post_file = None\n",
    "        for file in output_files:\n",
    "            if \"final\" in file.name.lower() or file.name.endswith(\".md\"):\n",
    "                final_post_file = file\n",
    "                break\n",
    "        \n",
    "        if not final_post_file and output_files:\n",
    "            final_post_file = max(output_files, key=lambda f: f.stat().st_mtime)\n",
    "        \n",
    "        if final_post_file:\n",
    "            try:\n",
    "                with open(final_post_file, 'r', encoding='utf-8') as f:\n",
    "                    final_post = f.read()\n",
    "                print(f\"\\nüì± Final social media post ({final_post_file.name}):\")\n",
    "                print(\"=\" * 60)\n",
    "                print(final_post)\n",
    "                print(\"=\" * 60)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error reading final post: {e}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No output files were created. Check the execution logs above.\")\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Let's test our system with a sample research paper and create a LinkedIn post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting social media post creation for LinkedIn...\n",
      "üìÑ Paper: QLoRA: Efficient Finetuning of Quantized LLMs\n",
      "üéØ Objective: Explain the benefits of QLoRA to machine learning practitioners and researchers\n",
      "============================================================\n",
      "ü§ñ [supervisor] Output:\n",
      "‚û°Ô∏è Next: SEARCH_AGENT\n",
      "--------------------------------------------------\n",
      "ü§ñ [SEARCH_AGENT] Output:\n",
      "Here's an engaging LinkedIn post about the research paper on QLoRA:\n",
      "\n",
      "---\n",
      "\n",
      "**Unlocking the Future of Machine Learning with QLoRA**\n",
      "\n",
      "üöÄ Exciting advancements in the field of machine learning are here! The recent paper titled **\"QLoRA: Efficient Finetuning of Quantized LLMs\"** introduces a groundbreaking approach to finetuning large language models (LLMs) with remarkable efficiency.\n",
      "\n",
      "üîç **What is QLoRA?**  \n",
      "QLoRA stands for Quantized Low-Rank Adaptation, a method that allows for the finetuning of LLMs with up to 65 billion parameters using only 2/3/4-bit precision on consumer-grade GPUs. This innovation is a game-changer for researchers and practitioners who face memory constraints while working with large models.\n",
      "\n",
      "üí° **Key Benefits:**  \n",
      "1. **Memory Efficiency:** QLoRA enables finetuning with significantly less memory compared to traditional methods, making it accessible for those with limited computational resources.  \n",
      "2. **Performance:** It achieves competitive results in various tasks such as text classification, natural language inference, and instruction following, even outperforming existing methods in some cases.  \n",
      "3. **User-Friendly:** The accompanying library, **llmtune**, simplifies the process of quantizing, running, and finetuning LLMs, allowing practitioners to focus on their research rather than technical hurdles.\n",
      "\n",
      "üåü **Why It Matters:**  \n",
      "As the demand for more powerful AI models grows, QLoRA provides a pathway for efficient model training and deployment, democratizing access to advanced machine learning capabilities. This is a significant step towards making cutting-edge AI technology available to a broader audience.\n",
      "\n",
      "üîó Dive into the full paper to explore the details and implications of this innovative approach!  \n",
      "#MachineLearning #AI #DeepLearning #QLoRA #Quantization #Research #Innovation\n",
      "\n",
      "--- \n",
      "\n",
      "Feel free to post this on LinkedIn to share the exciting developments in machine learning with your network!\n",
      "--------------------------------------------------\n",
      "ü§ñ [supervisor] Output:\n",
      "‚û°Ô∏è Next: COPY_EDITOR\n",
      "--------------------------------------------------\n",
      "ü§ñ [COPY_EDITOR] Output:\n",
      "The LinkedIn post about the research paper \"QLoRA: Efficient Finetuning of Quantized LLMs\" has been successfully created and saved. You can find it in the file `final_social_media_post.md`.\n",
      "--------------------------------------------------\n",
      "ü§ñ [supervisor] Output:\n",
      "‚û°Ô∏è Next: FINISH\n",
      "--------------------------------------------------\n",
      "‚úÖ Social media post creation completed!\n",
      "üìÅ Output files created: ['final_social_media_post.md']\n",
      "\n",
      "üì± Final social media post (final_social_media_post.md):\n",
      "============================================================\n",
      "**Unlocking the Future of Machine Learning with QLoRA**  \n",
      "\n",
      "üöÄ Exciting advancements in the field of machine learning are here! The recent paper titled **\"QLoRA: Efficient Finetuning of Quantized LLMs\"** introduces a groundbreaking approach to finetuning large language models (LLMs) with remarkable efficiency.  \n",
      "\n",
      "üîç **What is QLoRA?**  \n",
      "QLoRA stands for Quantized Low-Rank Adaptation, a method that allows for the finetuning of LLMs with up to 65 billion parameters using only 2/3/4-bit precision on consumer-grade GPUs. This innovation is a game-changer for researchers and practitioners who face memory constraints while working with large models.  \n",
      "\n",
      "üí° **Key Benefits:**  \n",
      "1. **Memory Efficiency:** QLoRA enables finetuning with significantly less memory compared to traditional methods, making it accessible for those with limited computational resources.  \n",
      "2. **Performance:** It achieves competitive results in various tasks such as text classification, natural language inference, and instruction following, even outperforming existing methods in some cases.  \n",
      "3. **User-Friendly:** The accompanying library, **llmtune**, simplifies the process of quantizing, running, and finetuning LLMs, allowing practitioners to focus on their research rather than technical hurdles.  \n",
      "\n",
      "üåü **Why It Matters:**  \n",
      "As the demand for more powerful AI models grows, QLoRA provides a pathway for efficient model training and deployment, democratizing access to advanced machine learning capabilities. This is a significant step towards making cutting-edge AI technology available to a broader audience.  \n",
      "\n",
      "üîó Dive into the full paper to explore the details and implications of this innovative approach!  \n",
      "#MachineLearning #AI #DeepLearning #QLoRA #Quantization #Research #Innovation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Example parameters\n",
    "paper_description = \"QLoRA: Efficient Finetuning of Quantized LLMs\"\n",
    "social_network = \"LinkedIn\"\n",
    "objective = \"Explain the benefits of QLoRA to machine learning practitioners and researchers\"\n",
    "\n",
    "# Create the social media post\n",
    "result = create_social_media_post(paper_description, social_network, objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Example: Twitter/X Post\n",
    "\n",
    "Let's create a different type of post for Twitter/X with a more concise approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting social media post creation for X...\n",
      "üìÑ Paper: Attention Is All You Need - Transformer architecture\n",
      "üéØ Objective: Generate excitement about the revolutionary impact of Transformers in AI\n",
      "============================================================\n",
      "ü§ñ [supervisor] Output:\n",
      "‚û°Ô∏è Next: SEARCH_AGENT\n",
      "--------------------------------------------------\n",
      "ü§ñ [SEARCH_AGENT] Output:\n",
      "Here's the engaging social media post for X about the research paper on Transformer architecture:\n",
      "\n",
      "---\n",
      "\n",
      "üöÄ‚ú® Exciting times in AI! The revolutionary paper \"Attention Is All You Need\" introduced the Transformer architecture, changing the game for natural language processing and beyond! üåçüí° \n",
      "\n",
      "Transformers leverage attention mechanisms to process data in parallel, making them faster and more efficient than traditional models. This innovation has paved the way for groundbreaking applications in translation, content generation, and even healthcare! üè•üìö \n",
      "\n",
      "Join the AI revolution and explore how Transformers are reshaping our world! #AI #Transformers #MachineLearning #Innovation\n",
      "\n",
      "--- \n",
      "\n",
      "This post is designed to generate excitement and highlight the transformative impact of Transformers in AI.\n",
      "--------------------------------------------------\n",
      "ü§ñ [supervisor] Output:\n",
      "‚û°Ô∏è Next: COPY_EDITOR\n",
      "--------------------------------------------------\n",
      "ü§ñ [COPY_EDITOR] Output:\n",
      "The engaging social media post for X about the Transformer architecture has been created and saved. You can find it in the file `final_social_media_post.md`.\n",
      "--------------------------------------------------\n",
      "ü§ñ [supervisor] Output:\n",
      "‚û°Ô∏è Next: FINISH\n",
      "--------------------------------------------------\n",
      "‚úÖ Social media post creation completed!\n",
      "üìÅ Output files created: ['final_social_media_post.md']\n",
      "\n",
      "üì± Final social media post (final_social_media_post.md):\n",
      "============================================================\n",
      "üöÄ‚ú® Exciting times in AI! The revolutionary paper \"Attention Is All You Need\" introduced the Transformer architecture, changing the game for natural language processing and beyond! üåçüí° \n",
      "\n",
      "Transformers leverage attention mechanisms to process data in parallel, making them faster and more efficient than traditional models. This innovation has paved the way for groundbreaking applications in translation, content generation, and even healthcare! üè•üìö \n",
      "\n",
      "Join the AI revolution and explore how Transformers are reshaping our world! #AI #Transformers #MachineLearning #Innovation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Example for Twitter/X\n",
    "paper_description = \"Attention Is All You Need - Transformer architecture\"\n",
    "social_network = \"X\"\n",
    "objective = \"Generate excitement about the revolutionary impact of Transformers in AI\"\n",
    "\n",
    "# Create the social media post\n",
    "result = create_social_media_post(paper_description, social_network, objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Usage\n",
    "\n",
    "You can modify the parameters below to test with different papers, social networks, and objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize these parameters for your own use case\n",
    "custom_paper_description = \"The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity\"  # Enter your paper description here\n",
    "custom_social_network = \"Facebook\"     # Choose: LinkedIn, X, or Facebook\n",
    "custom_objective = \"Key message: while AI is powerful, it is still at the very heart a tool and it still does not have the ability to problem solve and generalize like someone trained in mathematical problem solving\"          # Enter your objective here\n",
    "\n",
    "# Uncomment and run to test with your custom parameters\n",
    "# if custom_paper_description and custom_social_network and custom_objective:\n",
    "#     result = create_social_media_post(custom_paper_description, custom_social_network, custom_objective)\n",
    "# else:\n",
    "#     print(\"Please fill in all custom parameters above to test your own use case.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Summary\n",
    "\n",
    "This multi-agent LangGraph system successfully demonstrates:\n",
    "\n",
    "1. **Agent Coordination**: Multiple specialized agents working together through a supervisor\n",
    "2. **Tool Integration**: File management and arXiv search capabilities\n",
    "3. **Workflow Management**: Structured flow from research to final social media post\n",
    "4. **Platform Adaptation**: Content tailored to different social media platforms\n",
    "5. **LangSmith Integration**: Full tracing and monitoring capabilities\n",
    "\n",
    "The system produces markdown-formatted social media posts that are optimized for the target platform and objective, demonstrating the power of multi-agent coordination in content creation workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
